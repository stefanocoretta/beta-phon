---
title: A tutorial of Bayesian beta regressions with brms in R
author:
  - name: Stefano Coretta
    email: s.coretta@ed.ac.uk
    affiliations: 
        - id: uoe
          name: University of Edinburgh
          department: Linguistics and English Language
          address: 3 George Sq
          city: Edinburgh
          state: United Kingdom
          postal-code: EH8 9AD
    attributes:
        corresponding: true
    note: This is the first author footnote.
  - name: Paul Bürkner
    email: paul.buerkner@gmail.com
abstract: |
  This is the abstract. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum augue turpis, dictum non malesuada a, volutpat eget velit. Nam placerat turpis purus, eu tristique ex tincidunt et. Mauris sed augue eget turpis ultrices tincidunt. Sed et mi in leo porta egestas. Aliquam non laoreet velit. Nunc quis ex vitae eros aliquet auctor nec ac libero. Duis laoreet sapien eu mi luctus, in bibendum leo molestie. Sed hendrerit diam diam, ac dapibus nisl volutpat vitae. Aliquam bibendum varius libero, eu efficitur justo rutrum at. Sed at tempus elit.
keywords: 
  - keyword1
  - keyword2
date: last-modified
bibliography: 
  - linguistics.bib
  - statistics.bib
format:
  elsevier-pdf:
    keep-tex: true
    journal:
      name: Journal Name
      formatting: preprint
      model: 3p
      cite-style: authoryear
execute:
  cache: true
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
library(brms)
library(collapse)
```

# Introduction

Phonetic research often involves numeric continuous outcome variables, like durations, frequencies, loudness and ratios. Another commonly employed type of outcome variable are proportions: for example, proportion of voicing during closure, vocal folds contact quotient, gesture amplitude, nasalance. Moreover, virtually any measure can be MIN-MAX normalised, a procedure which transforms values so that they are in the range 0--1.

Regression models are very common, but there is a tendency of using Gaussian distribution families (i.e. probability distributions for the outcome variable) for anything that is numeric. A possible reason is that the base R function for fitting regression models, `lm()`, and the lme4 function used to fit regression models with varying terms, `lmer()`, both fit Gaussian regressions by default and the user does not have to specify the distribution family. This tacit defaulting to Gaussian models is also reflected in teaching practices, where test and models using the Gaussian distribution are the first to be taught, due to their relative simplicity and the fact that other models are generalisations of Gaussian models.

However, proportion are usually not Gaussian, since they are limited between 0 and 1. Thus, regression models with proportions as outcome variable should be fitted using a likelihood family that assumes such unit interval data. A common and flexible distribution for this purpose is the beta distribution. 
This tutorial introduces researchers to beta regression models in R using the package brms. Familiarity with regression modelling in R with a package like lme4 is assumed, but no prior knowledge of Bayesian statistics is necessary.

# The beta distribution

The beta distribution is often considered as *the* distribution for the modeling of unit interval data [@ferrari_beta_2004; @cribari-neto_beta_2010]. It has been extensively studied theoretically [@krysicki_new_1999; @gupta_handbook_2014; @espinheira_beta_2008] and is used a baseline to compare other unit interval distributions against [@kieschnick_regression_2003; @bonat_regression_2013; @lopez_bayesian_2013]. Specifically in Bayesian regression models, it was shown to perform well across a wide range of scenarios [@scholz_posterior_2023; @scholz_prediction_2025], which is why we focus on the beta distribution in this tutorial.

We use a common mean parameterization for the beta distribution with mean parameter $\mu$, bounded between 0 and 1, and positive precision parameter $\phi$ that is roughly proportional to the inverse of the variance $\text{Var}(y) = \frac{\mu \, (1 - \mu)}{\phi + 1}$. That is, the larger $\phi$ the smaller the variance of the corresponding beta distribution. While the mathematical details are not needed to understand the content of this tutorial, we still write down the density below for reasons of completeness:

$$
p(y \mid \mu, \phi) = \frac{1}{B(\mu \, \phi, \; (1-\mu) \, \phi)} \; y^{\mu \, \phi -1} \; (1-y)^{(1-\mu) \, \phi -1},
$$

where $B$ is the Beta function, a complex integral for whose numerical approximation efficient algorithms
exist in every programming language.

# Case study 1: voicing within consonant closure

For the first case study, we will model the proportion of voicing within consonant closure. The measurements come from a data set of audio and electroglottographic (EGG) recordings of 19 speakers of Northwestern Italian. The participants read frame sentences which included target words of the form /CVCo/, where /C/ was either /k, t, p/ in all permutations and /V/ was either /i, e, a, ɔ, u/ (two resulting words, /peto/ and /kako/ were excluded because they are profanities), for a total of 43 target words. There were 4 different frame sentence, with a total of 172 trials per participant (3,268 grand total). The actual observation count is 2,419, after removing speech errors, EGG measurement errors, and cases in which voicing ceased before the closure onset/after the closure offset of the second /C/.

The proportion of voicing during the closure of the second /C/ was calculated as the proportion of contiguous voicing duration after closure onset to total duration of closure. The following code chunk attaches the tidyverse packages (for reading and wrangling data) and loads the `ita_egg` tibble (data frame). The tibble is filtered so as to remove voicing proportions (`voi_clo_prop`) that are smaller than 0 and greater than 1. The variables `vowel` and `c2` are converted to factors to specify the order of the levels.

```{r}
#| label: read-ita-egg
#| message: false
#| warning: false

# attach tidyverse and set light theme for plots
library(tidyverse)
theme_set(theme_light())

# load tibble
load("data/coretta2018/ita_egg.rda")

# filter and mutate data
ita_egg <- ita_egg |> 
  filter(voi_clo_prop > 0, voi_clo_prop < 1) |> 
  mutate(
    vowel = factor(vowel, levels = c("i", "e", "a", "o", "u")),
    c2 = factor(c2, levels = c("k", "t", "p"))
  )
```

@tbl-ita-egg shows the first ten rows of the tibble (only relevant columns are included).

```{r}
#| label: tbl-ita-egg
#| tbl-cap: "First 10 rows of the data of voicing proportion within stop closure."
#| echo: false

ita_egg |> select(speaker, word, vowel, c2, voi_clo_prop) |> head(n = 10) |> knitr::kable()
```

@fig-ita-egg shows the raw voicing duration proportion values split by vowel /i, e, a, ɔ, u/ and second consonant /k, t, p/ in the /CVCo/ target words. The plot suggests that, on average, the voicing proportion is slightly lower with /k/ than with /t, p/. Moreover, there is greater variability between vowels in /t, p/ than in /k/. We will use a beta regression model to assess these patterns. \["expectations" XXX\]

```{r}
#| label: fig-ita-egg
#| fig-cap: "Proportion of voicing during the closure of the second consonant in /CVCo/ words by vowel and the second consonant."
#| echo: false

ita_egg |> 
  ggplot(aes(vowel, voi_clo_prop)) +
  geom_jitter(alpha = 0.2, width = 0.2, aes(colour = vowel)) +
  stat_summary(fun.data = "mean_cl_boot") +
  facet_grid(cols = vars(c2)) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    x = "Vowel", y = "Voicing during closure (prop)"
  ) +
  theme(legend.position = "none")
```

We will use brms to fit Bayesian beta regressions. \[XXX why Bayesian\]. The model has voicing proportion as the outcome variable and the following terms: an interaction between vowel (/i, e, a, ɔ, u/) and second consonant C2 (/k, t, p/), centred speech rate (number of syllables per second); as varying (aka random) terms, by-speaker varying coefficients for the vowel/consonant interaction and for centred speech rate.[^1] The categorical predictors vowel and C2 are coded using indexing rather than traditional R contrasts: in R, this corresponds to suppressing the model's intercept with the `0 +` syntax; using indexing instead of contrasts makes it easier to specify priors. For pedagogical simplicity, the model will use the default priors, but note that in real data analyses contexts, priors should be specified by the user. I refer the readers to XXX.

[^1]: Footnote about Gelman's terminology for random effects.

```{r}
#| label: voi-prop-bm
#| message: false

# attach brms
library(brms)

# fit the model
# Takes 3 minutes on MacBook Pro 2020, M1
voi_prop_bm <- brm(
  # model formula
  voi_clo_prop ~
    # constant terms
    0 + vowel:c2 + speech_rate_c +
    # varying terms
    (0 + vowel:c2 + speech_rate_c | speaker),
  # uses the beta family for the outcome
  family = Beta,
  data = ita_egg,
  cores = 4,
  seed = 3749,
  file = "data/cache/voi_prop_bm"
)
```

The `summary()` function prints the full model summary. For conciseness, we will use the `fixef()` function which prints the regression coefficients. \[EXPLAIN EXPECTED PREDICTIONS XXX\]. The full summary with an explanation of each part can be found in XXX. @tbl-voi-prop-fixef reports the output of `fixef()` as a table (we round all values to the nearest 2 digits for clarity.). For each coefficient in the model, `fixef()` prints the name of the coefficient, the mean estimate, the estimate error and the lower and upper limits of a Bayesian Credible interval (CrI). Here, we print an 80% CrI. There is nothing special about 95% CrI within Bayesian inference and instead experts recommend to check and report a variety of CrIs. Bayesian CrIs indicate that at a certain probability levels the "true" estimate lies within that interval: so, for example, a 90% CrI \[A, B\] indicates that there is a 90% probability that the "true" estimate is between A and B. Different probability levels correspond to different levels of confidence: the higher the probability the higher the confidence (always conditional on data and model). Obtaining CrIs at different probability levels allows researchers to make more fine-grained inferential statements than the frequentist significance dichotomy affords. For simplicity of exposition, we will use 80% CrIs in this case study but we strongly recommend researchers to always obtain CrIs at different levels of probability and base their inferences on all and not one in particular. To reiterate, in Bayesian inference, an 80% CrI indicates the range of values within which the true estimate falls at 80% probability or confidence.

```{r}
#| label: voi-prop-fixef
#| tbl-cap: "Regression coefficients of a beta regression of voicing proportion (`voi_prop_bm`)."
#| eval: false

fixef(voi_prop_bm, prob = c(0.1, 0.9))
```


```{r}
#| label: tbl-voi-prop-fixef
#| tbl-cap: "Regression coefficients of a beta regression of voicing proportion (`voi_prop_bm`)."
#| echo: false

round(
  fixef(voi_prop_bm, prob = c(0.1, 0.9)),
  digits = 2
) |> knitr::kable()
```

The coefficients of a beta regression are estimated on the log-odds scale, as in Bernoulli/binomial (aka logistic) regressions. From the summary, we see that speech rate (number of syllables per second) has a positive effect on voicing proportion: the 80% CrI is between 0.01 and 0.15 log-odds \[$\beta$ = 0.08, SD = 0.06\]. Log-odds can be converted to odd-ratios by exponentiating the value: 0.01-0.15 log odds correspond to an odd-ratio of 1.01 to 1.16, or as percentages, to an increase of voicing of 1 to 16% for every increase of one syllable per second. Since this is an 80% CrI, we can be 80% confident that the true effect of speech rate is between 1-16% increase of voicing proportion, conditional on the data and model. Note that transforming measures this way is appropriate *only* with quantile-based measures (like CrIs) but not with moments like the mean and standard deviation: to correctly get mean and SDs in the transformed scale, you must first extract the posterior draws (see below), convert them and then take moments such as mean and SD (for a more detailed explanation, see XXX). In the avoidance of doubt, we will always transform the drawn values first and then take summary measures.

Turning now to the coefficients for vowel and C2, given the indexing approach of coding these variables the model summary and the output of `fixef()` reports the *predictions* in log-odds for each combination of vowel and C2, rather than differences between levels. The CrIs of the vowel/C2 coefficients span all negative log-odds values: these correspond to proportions that are lower than 0.5 (which is 0 in log-odds). This matches the general trends in the raw data, which we plotted in @fig-ita-egg.

Next, we will plot the predicted proportions of each vowel/C2 combination at mean speech rate (i.e. centred speech rate = 0) and then calculate the average pair-wise difference in voicing proportion between /k, t, p/. Finally, we will assess whether there is greater between-vowel variability in /t, p/ relative to /k/.

Before being able to plot the predictions, it's important to get familiar with the so-called posterior draws. \[Bayesian MCMC XXX\]. Posterior draws can be conveniently obtained with the `as_draws_df()`. For the moment, we will extract only the draws of the constant regression coefficients (model variables starting with `b_`). To check which coefficients are available in a model, use `get_variables()` from the tidybayes package. `as_draws_df()` returns a tibble where each column contains the drawn values of a coefficient. @tbl-voi-prop-draws shows the first ten rows and first five columns of the output of `as_draws_df()`. The probability distribution of the drawn values of each coefficient is the posterior probability distribution of that coefficient. Note that, due to the indexing coding of vowel and C2, all coefficient except `b_speech_rate_c` are *predicted log-odds* for each vowel/C2 combination (the drawn values for `b_speech_rate_c` are drawn *differences* in log-odds for each unit increase of speech rate). The drawn values are in log-odds, but we can convert them to proportions with `plogis()` (we will do this when plotting below).

```{r}
#| label: voi-prop-bm-draws

# extract only coefficient variables starting with "b_"
voi_prop_bm_draws <- as_draws_df(voi_prop_bm, variable = "^b_", regex = TRUE)
```

```{r}
#| label: tbl-voi-prop-draws
#| tbl-cap: "First ten rows and 5 columns of the posterior draws for the model `voi_prop_bm`."
#| echo: false

voi_prop_bm_draws[,1:5] |> head(n = 10) |> knitr::kable()
```


We can now wrangle this tibble and plot the posterior distributions for each vowel/C2 combination. @tbl-voi-long shows the first ten rows.

```{r}
#| label: voi-prop-bm-draws-long
#| warning: false

voi_prop_bm_draws_long <- voi_prop_bm_draws |> 
  # drop b_speech_rate_c before pivoting
  select(-b_speech_rate_c) |> 
  # pivot vowel:c2 columns
  pivot_longer(`b_voweli:c2k`:`b_vowelu:c2p`, names_to = "coeff") |> 
  # separate "coeff" labels into type ("b"), vowel and c2
  separate(coeff, into = c("type", "vowel", "c2"))
```

```{r}
#| label: tbl-voi-long
#| tbl-cap: "First ten rows of posterior draws from `voi_prop_bm` in long format."
#| echo: false

voi_prop_bm_draws_long |> head(n = 10) |> knitr::kable()
```


For plotting, we can use ggplot2 statistics layers from the ggdist package. `stat_halfeye()` plots the density of the posterior probability (in grey), its median (point) and CrIs (lines). Let's use 60 and 80% CrIs and transform the log-odds values to proportions with `plogis()`. See @fig-voi-prop-bm-1.

```{r}
#| label: fig-voi-prop-bm-1
#| fig-cap: "Expected predictions of voicing proportion by vowel and consonant from `voi_prop_bm`."
#| message: false

# attach ggdist package
library(ggdist)

voi_prop_bm_draws_long |> 
  ggplot(aes(plogis(value), vowel)) +
  stat_halfeye(.width = c(0.6, 0.8)) +
  facet_grid(rows = vars(c2))
```

What if we want to plot the average predicted voicing proportion for the three consonants /k, t, p/? One approach is to take the mean across vowels within each consonant for each posterior draw, and the posterior distribution of the resulting list of values is the predicted posterior distribution of voicing proportion for each consonant, assuming an "average" vowel.

```{r}
#| label: voi-prop-bm-draws-long-c2

voi_prop_bm_draws_long_c2 <- voi_prop_bm_draws_long |> 
  # grouping by .draw and c2 ensures that averaging applies only within draw and c2
  group_by(.draw, c2) |> 
  # calculate the mean value within draw/c2
  summarise(
    value_mean = mean(value), .groups = "drop"
  )
```

```{r}
#| label: fig-voi-pbdl-c2
#| fig-cap: "Expected predictions of voicing proportion by consonant, averaged across vowels."
voi_prop_bm_draws_long_c2 |> 
  ggplot(aes(plogis(value_mean), c2)) +
  stat_halfeye(.width = c(0.6, 0.8))
```

Based on the expected posterior distributions of the mean voicing proportion by consonant, /p/ has a somewhat higher voicing proportion than /k/ and /t/. The real question is: how much higher? We can quantify this by taking the difference of the drawn values for /p/ and those for /t, k/ (all averaged across vowels). Since we want to compare /t, k/ with /p/, we should first average the average draws of /t, k/ and then take the difference of the averaged /t, k/ draws and the draws of /p/. @tbl-voi-pbd shows the first ten rows of the resulting data frame. The posterior distribution of the expected difference is shown in @fig-diff-p-tk.

```{r}
#| label: voi-prop-bm-diff

voi_prop_bm_diff <- voi_prop_bm_draws_long_c2 |> 
  # pivot data to create one column per consonant with the mean drawn values,
  # with one draw per raw
  pivot_wider(names_from = c2, values_from = value_mean) |> 
  mutate(
    # calculate the mean of /k/ and /t/, for each draw
    c2tk = mean(c(c2k, c2t)),
    # calculate the difference of /p/ and /t, k/
    c2p_tk_diff = c2p - c2tk
  )
```

```{r}
#| label: tbl-voi-pbd
#| tbl-cap: "First 10 rows of expected difference of voicing proportion between /t, k/ and /p/."
#| echo: false

voi_prop_bm_diff |> head(n = 10) |> knitr::kable()
```

```{r}
#| label: fig-diff-p-tk
#| fig-cap: "Posterior distribution of the difference between the expected voicing proportion of /t, k/ vs /p/, averaged across vowels."

voi_prop_bm_diff |> 
  ggplot(aes(c2p_tk_diff)) +
  stat_halfeye(.width = c(0.6, 0.8, 0.9)) +
  geom_vline(xintercept = 0)
```

Once we have the posterior difference, we can obtain CrIs of the difference using `quantile2()` from the posterior package. Beware that the values of the difference are in log-odds! We can convert these into odd-ratios with `exp()`. odd-ratios indicate the ratio of the difference between A and B, so that 1 means no difference, values greater than 1 indicate an increase in A relative to B and values lower than 1 indicate a decrease in A relative to B. odd-ratios are useful when looking at differences that are in log-odds because while the relative magnitude of the difference in proportion between two groups is the same independent of the baseline proportion, the *absolute* magnitude of the difference depends on the baseline value. For example, an odd-ratio difference of 1.25 would correspond to a proportion increase of 13 percentage points if the baseline proportion is 0.62 but it would correspond to a proportion increase of 17 percentage points if the baseline proportion is 0.73. Of course, in real research contexts it is still usefull to think about absolute magnitudes and their relevance from a conceptual and methodological perspective. In this tutorial we just focus on odd-ratios for simplicity.

```{r}
#| label: voi-prop-bm-diff-cri

library(posterior)

voi_prop_bm_diff |> 
  mutate(c2p_tk_diff_ratio = exp(c2p_tk_diff)) |> 
  reframe(
    # 90% CrI
    q90 = quantile2(c2p_tk_diff_ratio, probs = c(0.05, 0.95)),
    # 80% CrI
    q80 = quantile2(c2p_tk_diff_ratio, probs = c(0.1, 0.9)),
    # 60% CrI
    q60 = quantile2(c2p_tk_diff_ratio, probs = c(0.2, 0.8)),
  ) |> 
  # round to 2 digits
  mutate(across(everything(), ~round(.x, 2)))
```

So, based on the model and data, there is a 90% probability that the voicing proportion in /p/ is 1.07-1.38 times longer (or 7-38% increase) than in /t, k/. At 80% confidence, the change ratio is 1.10-1.34 (or 10-34% increase) while at 60% confidence is 1.14-1.30 (14-30% increase). In other words we can be quite confident that the voicing proportion in /p/ is longer than in /t, k/ and that the increase is less than 35%.

brms comes with a convenient function, `conditional_effects()`, to plot posterior means and CrIs based on predictors in the model. In the following example, we plot the predicted proportion of voicing by consonant and vowel.

```{r}
#| label: voi-prop-bm-cond
conditional_effects(voi_prop_bm, "c2:vowel")
```

Finally, the package marginaleffects [XXX] has two other convenience functions that return CrIs of comparisons across predictor levels (`avg_comparisons()`) and CrIs of posterior predictions across predictor levels (`avg_predictions`). \[XXX\]

```{r}
#| label: marginal

library(marginaleffects)

avg_comparisons(voi_prop_bm, variables = list(c2 = "pairwise"), conf_level = 0.8, type = "link")
avg_predictions(voi_prop_bm, variables = "vowel", conf_level = 0.8)
```

# Case study 2: coarticulatory vowel nasalisation

For the second case study we will use data from @carignan2021. The study looked at properties of nasality in German VNC sequences. Here, we will focus on the effect of C voicing (voiceless /t/ vs voiced /d/) on the proportion of nasalisation within the vowel in the VNC sequence. Previous work on coarticulatory nasalisation in English has suggested that vowels followed by an NC sequence where C is voiceless (NT) should show earlier coarticulatory nasalisation than vowels followed by an NC sequence where C is voiced [ND, see review in @carignan2021]. This pattern has been suggested to be driven by the articulatory and acoustic incompatibility of voicelessness and nasalisation, by which the velum opening gesture of the nasal consonant is pushed away (i.e. earlier) when the consonant following the nasal is voiceless. Everything else being equal, a greater proportion of vowel nasalisation (from the perspective of time) should be found in vowels followed by NT than in vowels followed by ND.

We will model the proportion of coarticulatory nasalisation in the German short vowels /i, e, a, o, u/ when followed by /nt/ or /nd/, using a Bayesian beta regression model. The proportion was calculated as the proportion of the nasal interval to the duration of the vowel. The nasal interval was defined thus: the interval between the time of peak velocity of velum opening to the offset of the vowel. We will use the results of the regression model to answer the following questions:

1.  Is the nasalisation proportion, on average across vowels, greater in voiceless NC sequences?
2.  Is there individual speaker variation?

First, let's read and plot the data.

```{r}
#| label: nasal
#| message: false
#| warning: false

nasal <- read_csv("data/carignan2021/nasal.csv")
nasal
```

-   `speaker` indicates the speaker ID.

-   `label` is the word label as given in the original data.

-   `vowel` is the target vowel in the VNC sequence.

-   `NC` is the NC sequence.

-   `voicing` indicates the voicing of C.

-   `nas_prop` is the proportion of coarticulatory nasalisation of the vowel.

```{r}
#| label: fig-nasal
#| fig-cap: "Proportion of coarticulatory nasalisation during the vowel in VNC sequences in German, depending on C voicing."
#| echo: false

nasal |> 
  ggplot(aes(vowel, nas_prop, colour = voicing)) +
  geom_jitter(position = position_jitterdodge(jitter.width = 0.2), alpha = 0.8) +
  scale_color_brewer(type = "qual") +
  labs(x = "Vowel", y = "Nasalisation proportion", colour = "C voicing")

```

@fig-nasal shows the proportion of coarticulatory nasalisation in vowels followed by /nd/ (voiced) vs /nt/ (voiceless) sequences, for the short vowels /i, e, a, o, u/. We can see a pattern of higher nasalisation proportion in vowels followed by /nt/, at least in the vowels /a, i, o/. For /e, u/, the distribution of nasalisation proportion seems to be similar between the voiced and voiceless contexts.

Now onto modelling with a beta regression. Note that a full appropriate model would include further predictors (both constant and varying), but for simplicity here we include only the following predictors: voicing (voiced /nd/ vs voiceless /nt/), vowel (/i, e, a, o, u/), including an interaction between them. As varying terms, we include a varying intercept by speaker and a by-speaker varying slope for voicing and vowel in interaction. As with the model from the first case study, voicing and vowel are coded using indexing, by suppressing the intercept with `0 +`. Here's the code of the model.

```{r}
#| label: nas-prop-bm

nas_prop_bm <- brm(
  nas_prop ~ 0 + voicing:vowel + (0 + voicing:vowel | speaker),
  data = nasal,
  family = Beta,
  cores = 4,
  seed = 3749,
  file = "data/cache/nas_prop_bm"
)
```

Let's inspect the output of `fixef()`.

```{r}
#| label: nas-prop-bm-fixef
round(
  fixef(nas_prop_bm, prob = c(0.1, 0.9)),
  digits = 2
)
```

Negative log-odds indicate a proportion that is smaller than 50%, while positive log-odds a proportion that is greater than 50%. Generally, the expected log-odd predictions are negative, indicating an overall tendency for the nasalisation to take less than 50% of the duration of the vowel. Moreover, the predictions are higher for voiceless NC sequences than for voiced NC sequences, indicating a greater proportion of nasalisation in the former. However there is vowel-specific variation, and there doesn't seem to be much of a difference in nasalisation proportion in /e/ and /u/. Plotting the expected predictions with `conditional_effects()` should make this clearer.

```{r}
#| label: nas-prop

conditional_effects(nas_prop_bm, "vowel:voicing")

```

Now that we fitted the model we can use the draws to answer the two research questions (repeated from above):

1.  Is the nasalisation proportion, on average across vowels, greater in voiceless NC sequences?
2.  Is there individual speaker variation?

To answer question 1, we can calculate the average difference in nasalisation proportion by first calculating the average nasalisation across all vowels for voiced and voiceless sequences and then take the difference of those, similarly to what we have done in the Case Study 1 above.

```{r}
#| label: nas-prop-bm-draws

# extract only coefficient variables starting with "b_"
nas_prop_bm_draws <- as_draws_df(nas_prop_bm, variable = "^b_", regex = TRUE)

nas_prop_bm_draws_long <- nas_prop_bm_draws |> 
  # pivot vowel:c2 columns
  pivot_longer(`b_voicingvoiced:vowela`:`b_voicingvoiceless:vowelu`, names_to = "coeff") |>
  # separate "coeff" labels into type ("b"), vowel and c2
  separate(coeff, into = c("type", "voicing", "vowel"))

nas_prop_bm_draws_long
```

Now let's calculate the mean nasalisation proportion within each draw by voicing, and plot the resulting posterior distributions. Note that, as discussed for Case study 1, when working wit log-odds it is important to first do all necessary calculations in log-odds, here calculate the mean log-odds across vowels, and *then* transform the calculated estimands to proportions/probabilities.

```{r}
#| label: nas-prop-bm-draws-long-voicing

nas_prop_bm_draws_long_voicing <- nas_prop_bm_draws_long |> 
  # grouping by .draw and voicing ensures that averaging applies only within draw and voicing
  group_by(.draw, voicing) |> 
  summarise(
    # calculate the mean value within draw/voicing in log-odds
    value_mean = mean(value),
    # we can now transform log-odds to proportion with plogis()
    value_mean_prop = plogis(value_mean),
    .groups = "drop"
  )

nas_prop_bm_draws_long_voicing
```

```{r}
#| label: nas-prop-bm-draws-long-voicing-plot

nas_prop_bm_draws_long_voicing |> 
  ggplot(aes(value_mean_prop, voicing)) +
  stat_halfeye(.width = c(0.6, 0.8))
```

The plot suggests an overall greater nasalisation proportion in voiceless NC sequences. Let's quantify how greater as we did in Case Study 1. We will use odd-ratios in this context as well, i.e. we will convert log-odds to odd-ratios using the `exp()` (exponential) function (and as before we first calculate the difference and then exponentiate the resulting values, after which we can take summary measures, like means and quantile-based measures such as CrIs).

```{r}
#| label: nas-prop-bm-diff

nas_prop_bm_diff <- nas_prop_bm_draws_long_voicing |> 
  # pivot data to create one column per voicing with the mean drawn values,
  # with one draw per raw. we need to drop the value_mean_prop col
  select(-value_mean_prop) |> 
  pivot_wider(names_from = voicing, values_from = value_mean) |> 
  mutate(
    # calculate the difference of voiceless and voiced in log-odds
    voicing_diff = voicingvoiceless - voicingvoiced,
    # now transform with exp() to get the ratio difference
    voicing_diff_ratio = exp(voicing_diff)
  )
nas_prop_bm_diff
```

```{r}
#| label: nas-prop-bm-diff-cris

nas_prop_bm_diff |> 
  reframe(
    # 90% CrI
    q90 = quantile2(voicing_diff_ratio, probs = c(0.05, 0.95)),
    # 80% CrI
    q80 = quantile2(voicing_diff_ratio, probs = c(0.1, 0.9)),
    # 60% CrI
    q60 = quantile2(voicing_diff_ratio, probs = c(0.2, 0.8)),
  ) |> 
  mutate(across(everything(), ~round(.x, 2)))
```

The CrIs of the ratio difference in nasalisation proportion in voiceless vs voiced NC sequences suggest a robust increase of nasalisation in the voiceless NC sequences, with a 90% probability that the increase is between 23% and 69% of the proportion in voiced NC sequences.

Moving onto question 2: is there individual speaker variation? [TAMMINGA XXX] For this, we will use the `spread_draws()` function from tidybayes [XXX] to extract the draws of the varying terms (in brms these are the coefficients that start with `r_`). There is quite a few steps of processing to get from the raw draws to the estimand we need: while we have commented the following code, we encourage readers to test each line sequentialy and inspect the intermediate output to fully understand the process. We assume that readers are familiar enough with models with varying terms (aka random effects, mixed-effects models). What readers should note is that to obtain the expected predictions of nasalisation proportion for each speaker, the constant terms and the varying terms should be added (since the varying terms indicate the deviation of each speaker from the overall estimate).

```{r}
#| label: nas-prop-r
#| message: false
#| warning: false
library(tidybayes)

nas_prop_r <- nas_prop_bm |> 
  # extract draws from model, only `r_speaker` varying terms
  spread_draws(r_speaker[speaker,voicingvowel]) |> 
  # separate the column voicingvowel to two columns
  separate(voicingvowel, c("voicing", "vowel")) |> 
  # join the draws with the `b_` terms
  left_join(y = nas_prop_bm_draws_long) |> 
  # get the expected log-odd value of each speaker, in each draw
  # this is the sum of the `value` from the b_ terms and the value from the
  # r_speaker term.
  mutate(r_speaker_value = value + r_speaker) |> 
  # group the data for summarise
  group_by(.draw, speaker, voicing) |> 
  # get mean expected log-odds by draw, speaker and voicing (averaging across vowel)
  summarise(r_speaker_value_mean = mean(r_speaker_value)) |> 
  # make the data wider: two columns, one for voiced and one for voiceless
  pivot_wider(names_from = voicing, values_from = r_speaker_value_mean) |> 
  # finally, calculate the difference in expected log-odds of voiceless and voiced
  mutate(voicing_diff = voicingvoiceless - voicingvoiced)

nas_prop_r
```

@fig-nas-prop-r plots the posterior distributions of the expected log-odd difference of coarticulatory nasalisation in voiceless vs voiced NC sequences (*x*-axis), for each speaker in the data (*y*-axis), as predicted by the model. The red solid vertical line indicates the constant (overall) expected log-odd difference based on the (constant) `b_` terms. The black dashed vertical line marks log-difference 0 (i.e., no difference in proportion of nasalisation between voiceless and voiced NC).

```{r}
#| label: fig-nas-prop-r
#| warning: false
#| fig-asp: 1.5

nas_prop_r |> 
  ggplot(aes(voicing_diff, reorder(speaker, voicing_diff))) +
  stat_halfeye() +
  geom_vline(xintercept = mean(nas_prop_bm_diff$voicing_diff), colour = "red") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  lims(x = c(-1, 1.5))
```

There is a lot of uncertainty within and between speakers: while the distributions of most speakers are located in the positive range, some expected distributions (see last 5 speakers at the bottom of figure) do substantially span both negative and positive values. In other words, while most speakers are more likely to have a larger nasalisation proportion in voiceless NC sequences, a few might in fact have the opposite pattern. Even among those speakers that do have a more robust positive difference, there is a lot of uncertainty as to the magnitude of the difference.


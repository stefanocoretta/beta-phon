---
title: "Bayesian beta regressions with brms in R: A tutorial for phoneticians"
author:
  - name: Stefano Coretta
    email: s.coretta@ed.ac.uk
    affiliations: 
        - id: uoe
          name: University of Edinburgh
          department: Linguistics and English Language
          address: 3 George Sq
          city: Edinburgh, United Kingdom
          postal-code: EH8 9AD
    attributes:
        corresponding: true
    note: This is the first author footnote.
  - name: Paul Bürkner
    email: paul.buerkner@gmail.com
    affiliations:
        - id: dort
          name: TU Dortmund University
          department: Department of Statistics
          adress: Technische Universität Dortmund
          city: Dortmund, Germany
          postal-code: 44221
abstract: |
  Phonetic research frequently involves analyzing numeric continuous outcome variables, such as durations, frequencies, loudness, and ratios. Another commonly used outcome type is proportions, including measures like the proportion of voicing during closure, gesture amplitude, and nasalance. Despite their bounded nature, proportions are often modeled using Gaussian regression, largely due to the default settings of commonly used statistical functions in R (e.g., lm() and lmer() from lme4). This practice persists in teaching and research, despite the fact that Gaussian models assume unbounded continuous data and may poorly fit proportion data. To address this issue, this tutorial introduces beta regression models, a more appropriate statistical approach for analyzing proportions. The beta distribution provides a flexible framework for modelling continuous data constrained between 0 and 1. The tutorial employs the brms package in R and assumes familiarity with regression modeling but no prior knowledge of Bayesian statistics. The tutorial includes two case studies illustrating the practical implementation of Bayesian beta regression models. Data and code are available at <https://github.com/stefanocoretta/beta-phon>.
keywords: 
  - acoustics
  - articulation
  - proportions
  - Bayesian regressions
  - beta distribution
date: last-modified
bibliography: 
  - linguistics.bib
  - statistics.bib
format:
  elsevier-pdf:
    keep-tex: true
    journal:
      name: Journal Name
      formatting: preprint
      model: 3p
      cite-style: authoryear
  elsevier-html: default
execute:
  cache: true
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
theme_set(theme_light())
library(brms)
library(collapse)
library(marginaleffects)
library(posterior)
```

# Introduction

Phonetic research often involves numeric continuous outcome variables, like durations, frequencies, loudness and ratios [@kluender1988; @johnson2003; @gick2013; @ladefoged2014; @abramson2017; @roettger2018; @coretta2023; @rosen2005]. Another commonly employed type of outcome variable are proportions: for example, proportion of voicing during closure [@davidson2016], vocal folds contact quotient [@herbst2017], gesture amplitude [@carignan2021], nasalance [@carignan2021]. Moreover, virtually any measure can be MIN-MAX normalised, a procedure which transforms values so that they are in the range 0--1.

Regression models (and extensions like generalised additive models) have become a *de facto* standard for the statistical analysis of a variety of measures in phonetic research [@kirby2018; @politzerahles2018; @tavakoli2024]. However, there is a tendency for researchers to use Gaussian distribution families (i.e. probability distributions for the outcome variable) for any measure that is numeric, irrespective of whether the measure is unbounded, like in truly Gaussian variables, or bounded, like in proportions. A possible reason is that the base R function for fitting regression models, `lm()`, and the lme4 function used to fit regression models with varying terms, `lmer()` from lme4 [@bates2015], both fit Gaussian regressions by default and the user does not have to specify the distribution family. This tacit default of using Gaussian models is also reflected in teaching practices, where significance test and models using the Gaussian distribution are the first to be taught [@baayen2008; @winter2020], due to their relative simplicity and the fact that regression models with other families are conceptual generalisations of Gaussian regression models. @fig-bg shows how poorly a Gaussian regression model fits beta-distributed data: the dark blue line is the density of data simulated to be distributed according to a beta distribution; the light blue lines are predicted distributions as generated by a Gaussian model of the data. The predicted Gaussian distributions over-predict values between 0.5 and 0.75 and under-predict values between 0.75 and 1. Moreover, the density peak (median) of the Gaussian distributions is lower than the peak in the original data.

```{r}
#| label: fig-bg
#| fig-cap: "Gaussian model fitted to beta-distributed data. The dark blue line is the density of the beta data, while the light blue lines are simulated densities of the same data based on a Gaussian model."
#| echo: false

bg <- brm(
  x ~ 1,
  data = data.frame(x),
  file = "data/cache/bg"
)

pp_check(bg, ndraws = 10)
```

While most researchers approach proportions with Gaussian regression models, proportion are not Gaussian by nature, since they are continuous variables bounded between 0 and 1. Thus, regression models with proportions as outcome variable should be fitted using a likelihood family that assumes such unit interval data. A common and flexible distribution for this purpose is the beta distribution. This tutorial introduces researchers to beta regression models in R using the package brms. Familiarity with regression modelling in R with a package like lme4 is assumed, but no prior knowledge of Bayesian statistics is necessary. The rest of the paper is structured as follows: @sec-beta introduces the mathematical underpinnings of the beta distribution, @sec-bayes provides the readers with a brief explanation and justification of Bayesian regression models, while @sec-case-1 and @sec-case-2 illustrate how to fit Bayesian beta regression models with two case studies. The research compendium with data and code can be found at <https://github.com/stefanocoretta/beta-phon>.

# The beta distribution {#sec-beta}

The beta distribution is often considered as *the* distribution for the modelling of unit interval data [@ferrari_beta_2004; @cribari-neto_beta_2010]. It has been extensively studied theoretically [@krysicki_new_1999; @gupta_handbook_2014; @espinheira_beta_2008] and is used a baseline to compare other unit interval distributions against [@kieschnick_regression_2003; @bonat_regression_2013; @lopez_bayesian_2013]. Specifically in Bayesian regression models, it was shown to perform well across a wide range of scenarios [@scholz_posterior_2023; @scholz_prediction_2025], which is why we focus on the beta distribution in this tutorial.

We use a common mean parametrisation for the beta distribution with mean parameter $\mu$, bounded between 0 and 1, and positive precision parameter $\phi$ that is roughly proportional to the inverse of the variance $\text{Var}(y) = \frac{\mu \, (1 - \mu)}{\phi + 1}$. That is, the larger $\phi$ the smaller the variance of the corresponding beta distribution. While the mathematical details are not needed to understand the content of this tutorial, we still write down the density below for reasons of completeness:

$$
p(y \mid \mu, \phi) = \frac{1}{B(\mu \, \phi, \; (1-\mu) \, \phi)} \; y^{\mu \, \phi -1} \; (1-y)^{(1-\mu) \, \phi -1},
$$

where $B$ is the Beta function, a complex integral for whose numerical approximation efficient algorithms exist in every programming language.

# Bayesian regression models {#sec-bayes}

Bayesian regression models are being increasingly adopted within phonetics and language research more broadly [@vasishth2018; @nalborczyk2019; @verissimo2021]. Bayesian inference involves updating of prior probability distributions in light of evidence from data, to produce posterior probability distributions. In Bayesian regression models, model parameters are modelled as full probability distributions, rather than point estimates as in Null Hypothesis Significance Testing. Given the difficulty of analytical solutions of model equations, Bayesian regressions rely on sampling algorithms to reconstruct the posterior distributions. The statistical language Stan [@standevelopmentteam2017] employs efficient and robust Markov Chain Monte Carlo algorithms for fitting a variety of models, and the R package brms allows R users to interface with Stan from within R to fit Bayesian regression models [@burkner2017; @burkner2018; @burkner2021].

The main practical advantage of Bayesian regression models over maximum-likelihood-based frequentist regression models, like those fitted with the lme4 package [@bates2015], is that Bayesian regression models don't suffer from the convergence issues that models fitted in lme4 [@bates2015] and other packages [@cribarineto2010] that fit frequentist models do, independent of sample size. A second, long-term advantage is that Bayesian regression models allow researchers to statistically re-use information from previous studies by specifying informative priors. While prior specification is one of the main features of Bayesian inference, in this tutorial we will use the default priors as set by brms. These are sensible priors estimated from the data that facilitate convergence but bear virtually no influence on the estimated posteriors. Specifying priors requires a great deal of precise quantitative knowledge, which in most areas of phonetics we still do not possess, so that using default uninformative priors is, for the time being, theoretically sound. For practical guidance on prior specification, see <https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations>.

The output of Bayesian regression models is (posterior) probability distributions for the model parameters, through which researchers can quantify (un)certainty. Bayesian Credible Intervals (CrIs) can be calculated from the posterior distributions at several probability levels (e.g. 95, 90, 80, 60%) for a more complete view on estimated parameters. Bayesian CrIs indicate that, at a certain probability level, the parameter's estimate lies within that interval: so, for example, a 90% CrI \[A, B\] indicates that there is a 90% probability that the estimate is between A and B. Different probability levels correspond to different levels of confidence: the higher the probability the higher the confidence (always conditional on data and model). Readers interested in a full and accessible exposition of Bayesian statistics are referred to @mcelreath2019. Shorter introductions can be found in @etz2018, @vasishth2018 and @nalborczyk2019.

# Case study 1: coarticulatory voicing within consonant closure {#sec-case-1}

For the first case study, we will model the proportion of coarticulatory progressive voicing within the consonant closure of voiceless stops. The measurements come from a data set of audio and electroglottographic (EGG) recordings of 19 speakers of Northwestern Italian [@coretta2019k; @coretta2020b]. The participants read frame sentences which included target words of the form /CVCo/, where C was either /k, t, p/ in all permutations and V was either /i, e, a, o, u/ (two resulting words, /peto/ and /kako/ were excluded because they are profanities), for a total of 43 target words. There were 4 different frame sentence: *Scrivete X sul foglio* 'Write X on the sheet', *Ha detto X sei volte* 'She said X six times', *Sentivo X di nuovo* 'I heard X again', *Ripete X da sempre* 'She's been repeating X since ever'. There is a total of 172 trials per participant (3,268 grand total). The actual observation count is 2,419, after removing speech errors, EGG measurement errors, and cases in which voicing ceased before the closure onset/after the closure offset of the second consonant in the target word.

The proportion of voicing during the closure of the second consonant was calculated as the proportion of contiguous voicing duration after closure onset to total duration of closure. The following code chunk attaches the tidyverse packages [for reading and wrangling data, @wickham2019] and loads the `ita_egg` tibble (data frame). The tibble is filtered so as to remove voicing proportions (`voi_clo_prop`) that are smaller than 0 and greater than 1. The variables `vowel` (first vowel in the target word) and `c2` (second consonant in the target word) are converted to factors to specify the order of the levels. @tbl-ita-egg shows the first ten rows of the tibble (only relevant columns are included).

```{r}
#| label: read-ita-egg
#| message: false
#| warning: false

# attach tidyverse and set light theme for plots
library(tidyverse)
theme_set(theme_light())

# load tibble
load("data/coretta2018/ita_egg.rda")

# filter and mutate data
ita_egg <- ita_egg |> 
  filter(voi_clo_prop > 0, voi_clo_prop < 1) |> 
  mutate(
    vowel = factor(vowel, levels = c("i", "e", "a", "o", "u")),
    c2 = factor(c2, levels = c("k", "t", "p"))
  )
```

```{r}
#| label: tbl-ita-egg
#| tbl-cap: "First 10 rows of the data of voicing proportion within stop closure."
#| echo: false

ita_egg |> select(speaker, word, vowel, c2, voi_clo_prop) |> head(n = 10) |> knitr::kable()
```

@fig-ita-egg shows the raw voicing duration proportion values split by vowel /i, e, a, o, u/ and second consonant /k, t, p/ in the /CVCo/ target words. The plot suggests that, on average, the voicing proportion is slightly lower with /k/ than with /t, p/. Moreover, there is greater variability between vowels in /t, p/ than in /k/. We will use a beta regression model to assess whether the place of articulation of the consonant affects the proportion of coarticulatory progressive voicing, while averaging across vowels (of course, another question that could be answered with the same model is if different vowels lead to different voicing proportions, but for sake of space we restrict this tutorial to the former question). A general expectation is that the proportion of progressive voicing should increase with fronter places of articulation (so from /k/ to /t/ to /p/) given the aerodynamic constraints which obtain with vocal fold vibration during a fully occluded oral tract [@vandenberg1958; @rothenberg1967; @ohala2011].

```{r}
#| label: fig-ita-egg
#| fig-cap: "Proportion of voicing during the closure of the second consonant in /CVCo/ words by vowel and the second consonant."
#| echo: false

ita_egg |> 
  ggplot(aes(vowel, voi_clo_prop)) +
  geom_jitter(alpha = 0.2, width = 0.2, aes(colour = vowel)) +
  stat_summary(fun.data = "mean_cl_boot") +
  facet_grid(cols = vars(c2)) +
  scale_color_brewer(palette = "Dark2") +
  labs(
    x = "Vowel", y = "Voicing during closure (prop)"
  ) +
  theme(legend.position = "none")
```

We will use brms to fit a Bayesian beta regression [@burkner2017]. The model has voicing proportion as the outcome variable and the following terms: an interaction between vowel (/i, e, a, o, u/) and second consonant C2 (/k, t, p/), centred speech rate (number of syllables per second); as varying (aka random) terms, we included by-speaker varying coefficients for the vowel/consonant interaction and for centred speech rate.[^1] The categorical predictors vowel and C2 are coded using indexing rather than the traditional R contrasts, as advocated in @mcelreath2019: in R, this corresponds to suppressing the model's intercept with the `0 +` syntax; using indexing instead of contrasts makes it easier to specify priors and uncertainty is distributed equally across all levels of categorical predictors. For pedagogical simplicity, the model will use the default priors as explained in @sec-bayes.

[^1]: While the terms "random effects, intercept and slopes" are commonly employed in applied statistical work in linguistics and phonetics, we opt to use the conceptually more appropriate terminology proposed by @gelman2005: varying terms, intercepts, slopes, coefficients. Other common terms are multilevel and hierarchical terms.

```{r}
#| label: voi-prop-bm
#| message: false

# attach brms
library(brms)

# fit the model
# Takes 3 minutes on MacBook Pro 2020, M1
voi_prop_bm <- brm(
  # model formula
  voi_clo_prop ~
    # constant terms
    0 + vowel:c2 + speech_rate_c +
    # varying terms
    (0 + vowel:c2 + speech_rate_c | speaker),
  # uses the beta family for the outcome
  family = Beta,
  data = ita_egg,
  cores = 4,
  seed = 3749,
  file = "data/cache/voi_prop_bm"
)
```

The `summary()` function prints the full model summary. For conciseness, we will use the `fixef()` function which prints the regression coefficients. @tbl-voi-prop-fixef reports the output of `fixef()` as a table (we round all values to the nearest 2 digits for clarity.). For each coefficient in the model, `fixef()` prints the name of the coefficient, the mean estimate, the estimate error and the lower and upper limits of a Bayesian Credible interval (CrI). Note that all values are in log-odds, since the link function in beta regressions is the logistic function, like in binomial/Bernoulli regressions. Here, we print an 80% CrI. There is nothing special about 95% CrI within Bayesian inference and instead experts recommend to check and report a variety of CrIs. Obtaining CrIs at different probability levels allows researchers to make more fine-grained inferential statements than the frequentist significance dichotomy affords. For simplicity of exposition, we will use 80% CrIs in this case study but we strongly recommend researchers to always obtain CrIs at different levels of probability and base their inferences on all and not one in particular. To reiterate, in Bayesian inference, an 80% CrI indicates the range of values within which the true estimate falls at 80% probability or confidence.

```{r}
#| label: voi-prop-fixef
#| eval: false

fixef(voi_prop_bm, prob = c(0.1, 0.9))
```

```{r}
#| label: tbl-voi-prop-fixef
#| tbl-cap: "Regression coefficients of a beta regression of voicing proportion (`voi_prop_bm`)."
#| echo: false

round(
  fixef(voi_prop_bm, prob = c(0.1, 0.9)),
  digits = 2
) |> knitr::kable()
```

From the summary, we see that speech rate (number of syllables per second) has a positive effect on voicing proportion: the 80% CrI is between 0.01 and 0.15 log-odds [$\beta$ = 0.08, SD = 0.06]. Log-odds can be converted to odd-ratios by exponentiating the value: 0.01-0.15 log odds correspond to an odd-ratio of 1.01 to 1.16, or as percentages, to an increase of voicing of 1 to 16% for every increase of one syllable per second. Since this is an 80% CrI, we can be 80% confident that the true effect of speech rate is between 1-16% increase of voicing proportion, conditional on the data and model. Note that transforming measures this way is appropriate *only* with quantile-based measures (like CrIs) but not with moments like the mean and standard deviation: to correctly get mean and SDs in the transformed scale, you must first extract the posterior draws (see below), convert them and then take moments such as mean and SD [for a more detailed explanation, see @burkner2025, p. 101]. In the avoidance of doubt, we will always transform the drawn values first and then take summary measures.

Turning now to the coefficients for vowel and C2, given the indexing approach of coding these variables the model summary and the output of `fixef()` reports the *predictions* in log-odds for each combination of vowel and C2, rather than differences between levels. The CrIs of the vowel/C2 coefficients span all negative log-odds values: these correspond to proportions that are lower than 0.5 (which is 0 in log-odds). This matches the general trends in the raw data, which we plotted in @fig-ita-egg. Next, we will plot the predicted proportions of each vowel/C2 combination at mean speech rate (i.e. centred speech rate = 0) and then calculate the average pair-wise difference in voicing proportion between /k, t, p/.

Before being able to plot the predictions, it's important to get familiar with the so-called posterior draws. Bayesian regression models are fitted using Markov Chain Monte Carlo (MCMC) methods, as briefly explained in @sec-bayes. The `brm()` function runs four MCMC chains with 2000 iterations each by default. These are sufficient in most cases. The first 1000 iterations of each chain are used for "warmup", where the MCMC algorithm is optimised to find the posterior probability. The second half of the iterations, 1000 per chain, are used for sampling from the posterior probability. Each iteration returns a drawn value for each parameter in the model. The list of values drawn during the Monte Carlo sampling are called the "posterior draws". Since four chains are run, a total of 4000 posterior values are generated. The posterior draws are used for inference: we can plot them, summarise them, transform them and combine them in any way to answer specific questions.

Posterior draws can be conveniently obtained with the `as_draws_df()` from brms. For the moment, we will extract only the draws of the constant (aka fixed) regression coefficients (model variables starting with `b_`). To check which coefficients are available in a model, use `get_variables()` from the tidybayes package [@kay2019]. `as_draws_df()` returns a tibble where each column contains the drawn values of a coefficient. @tbl-voi-prop-draws shows the first ten rows and first five columns of the output of `as_draws_df()`. The probability distribution of the drawn values of each coefficient is the posterior probability distribution of that coefficient. Note that, due to the indexing coding of vowel and C2, all coefficient except `b_speech_rate_c` are drawn *log-odds values* for each vowel/C2 combination (the drawn values for `b_speech_rate_c` are drawn *differences* in log-odds values for each unit increase of speech rate). The drawn values are in log-odds, but we can convert them to proportions with `plogis()` (we will do this when plotting below).

```{r}
#| label: voi-prop-bm-draws
#| warning: false

# extract only coefficient variables starting with "b_"
voi_prop_bm_draws <- as_draws_df(voi_prop_bm, variable = "^b_", regex = TRUE)
```

```{r}
#| label: tbl-voi-prop-draws
#| tbl-cap: "First ten rows and 5 columns of the posterior draws for the model `voi_prop_bm`."
#| echo: false

voi_prop_bm_draws[,1:5] |> head(n = 10) |> knitr::kable()
```

We can now wrangle this tibble and plot the posterior distributions for each vowel/C2 combination. @tbl-voi-long shows the first ten rows.

```{r}
#| label: voi-prop-bm-draws-long
#| warning: false

voi_prop_bm_draws_long <- voi_prop_bm_draws |> 
  # drop b_speech_rate_c before pivoting
  select(-b_speech_rate_c) |> 
  # pivot vowel:c2 columns
  pivot_longer(`b_voweli:c2k`:`b_vowelu:c2p`, names_to = "coeff") |> 
  # separate "coeff" labels into type ("b"), vowel and c2
  separate(coeff, into = c("type", "vowel", "c2"))
```

```{r}
#| label: tbl-voi-long
#| tbl-cap: "First ten rows of posterior draws from `voi_prop_bm` in long format."
#| echo: false

voi_prop_bm_draws_long |> head(n = 10) |> knitr::kable()
```

For plotting, we can use ggplot2 statistics layers from the ggdist package [@kay2023; kay2024]. `stat_halfeye()` plots the density of the posterior probability (in grey), its median (point) and CrIs (lines). Let's use 60 and 80% CrIs and transform the log-odds values to proportions with `plogis()`. See @fig-voi-prop-bm-1.

```{r}
#| label: fig-voi-prop-bm-1
#| fig-cap: "Expected predictions of voicing proportion by vowel and consonant from `voi_prop_bm`."
#| message: false

# attach ggdist package
library(ggdist)

voi_prop_bm_draws_long |> 
  ggplot(aes(plogis(value), vowel)) +
  stat_halfeye(.width = c(0.6, 0.8)) +
  facet_grid(rows = vars(c2)) +
  labs(
    caption = "The points are the medians and the two lines are 60 and 80% CrIs."
  )
```

What if we want to plot the average predicted voicing proportion for the three consonants /k, t, p/? One approach is to take the mean across vowels within each consonant for each posterior draw, and the posterior distribution of the resulting list of values is the predicted posterior distribution of voicing proportion for each consonant, assuming an "average" vowel. See @fig-voi-pbdl-c2.

```{r}
#| label: voi-prop-bm-draws-long-c2

voi_prop_bm_draws_long_c2 <- voi_prop_bm_draws_long |> 
  # grouping by .draw and c2 ensures that averaging applies only within draw and c2
  group_by(.draw, c2) |> 
  # calculate the mean value within draw/c2
  summarise(
    value_mean = mean(value), .groups = "drop"
  )
```

```{r}
#| label: fig-voi-pbdl-c2
#| fig-cap: "Expected predictions of voicing proportion by consonant, averaged across vowels."
voi_prop_bm_draws_long_c2 |> 
  ggplot(aes(plogis(value_mean), c2)) +
  stat_halfeye(.width = c(0.6, 0.8)) +
  labs(
    caption = "The points are the medians and the two lines are 60 and 80% CrIs."
  )
```

Based on the expected posterior distributions of the mean voicing proportion by consonant, /p/ has a somewhat higher voicing proportion than /k/ and /t/. The real question is: how much higher? We can quantify this by taking the difference of the drawn values for /p/ and those for /t, k/ (all averaged across vowels). Since we want to compare /t, k/ with /p/, we should first average the average draws of /t, k/ and then take the difference of the averaged /t, k/ draws and the draws of /p/. @tbl-voi-pbd shows the first ten rows of the resulting data frame. The posterior distribution of the expected difference is shown in @fig-diff-p-tk.

```{r}
#| label: voi-prop-bm-diff

voi_prop_bm_diff <- voi_prop_bm_draws_long_c2 |> 
  # pivot data to create one column per consonant with the mean drawn values,
  # with one draw per raw
  pivot_wider(names_from = c2, values_from = value_mean) |> 
  mutate(
    # calculate the mean of /k/ and /t/, for each draw
    c2tk = mean(c(c2k, c2t)),
    # calculate the difference of /p/ and /t, k/
    c2p_tk_diff = c2p - c2tk
  )
```

```{r}
#| label: tbl-voi-pbd
#| tbl-cap: "First 10 rows of expected difference of voicing proportion between /t, k/ and /p/."
#| echo: false

voi_prop_bm_diff |> head(n = 10) |> knitr::kable()
```

```{r}
#| label: fig-diff-p-tk
#| fig-cap: "Posterior distribution of the difference between the expected voicing proportion of /t, k/ vs /p/, averaged across vowels."

voi_prop_bm_diff |> 
  ggplot(aes(c2p_tk_diff)) +
  stat_halfeye(.width = c(0.6, 0.8, 0.9)) +
  geom_vline(xintercept = 0)
```

Once we have the posterior difference, we can obtain CrIs of the difference using `quantile2()` from the posterior package [@burkner2024]. Beware that the values of the difference are in log-odds! We can convert these into odd-ratios with `exp()`. The output of the code below is shown in @tbl-voi-bm-quant. Odd-ratios indicate the ratio of the difference between A and B, so that 1 means no difference, values greater than 1 indicate an increase in A relative to B and values lower than 1 indicate a decrease in A relative to B. Odd-ratios are useful when looking at differences that are in log-odds because while the relative magnitude of the difference in proportion between two groups is the same independent of the baseline proportion, the *absolute* magnitude of the difference depends on the baseline value. For example, an odd-ratio difference of 1.25 would correspond to a proportion increase of about 3 percentage points if the baseline proportion is 0.62 but it would correspond to a proportion increase of 5 percentage points if the baseline proportion is 0.73 and 1 percentage point if the baseline is 0.99. Of course, in real research contexts it is still useful to think about absolute magnitudes and their relevance from a conceptual and methodological perspective. In this tutorial we just focus on odd-ratios for simplicity.

```{r}
#| label: odds
#| include: false
#| eval: false

logs <- qlogis(0.62)
p <- plogis(logs * 1.25)
round(p - 0.62, 2)

logs <- qlogis(0.73)
p <- plogis(logs * 1.25)
round(p - 0.73, 2)

logs <- qlogis(0.99)
p <- plogis(logs * 1.25)
round(p - 0.99, 2)
```

```{r}
#| label: voi-prop-bm-diff-cri
#| message: false

library(posterior)

voi_bm_quant <- voi_prop_bm_diff |> 
  mutate(c2p_tk_diff_ratio = exp(c2p_tk_diff)) |> 
  reframe(
    # 90% CrI
    q90 = quantile2(c2p_tk_diff_ratio, probs = c(0.05, 0.95)),
    # 80% CrI
    q80 = quantile2(c2p_tk_diff_ratio, probs = c(0.1, 0.9)),
    # 60% CrI
    q60 = quantile2(c2p_tk_diff_ratio, probs = c(0.2, 0.8)),
  ) |> 
  # round to 2 digits
  mutate(across(everything(), ~round(.x, 2)))
```

```{r}
#| label: tbl-voi-bm-quant
#| tbl-cap: "Upper and lower limits of 90, 80 and 60% Credible Intervals of the difference ratio of voicing proportion in /t, k/ vs /p/."
#| echo: false

voi_bm_quant |> knitr::kable()
```

Based on the model and data, there is a 90% probability that the voicing proportion in /p/ is 1.07-1.38 times longer (or 7-38% increase) than in /t, k/. At 80% confidence, the change ratio is 1.10-1.34 (or 10-34% increase) while at 60% confidence is 1.14-1.30 (14-30% increase). In other words we can be quite confident that the voicing proportion in /p/ is greater than in /t, k/ and that the increase is less than 35%. The brms package comes with a convenient function, `conditional_effects()`, to plot posterior means and CrIs based on predictors in the model. In @fig-voi-prop-bm-cond, we plot the predicted proportion of voicing by consonant and vowel.

```{r}
#| label: fig-voi-prop-bm-cond
#| fig-cap: "Expected voicing proportion by consonant and vowel with 95% Credible Intervals."
conditional_effects(voi_prop_bm, "c2:vowel")
```

Finally, the package marginaleffects [@arelbundock2025] has two other convenience functions that return CrIs of comparisons across predictor levels (`avg_comparisons()`) and CrIs of posterior predictions across predictor levels (`avg_predictions`). Both functions take the model and a list of variables as arguments. Optionally, you can set the confidence level with the `conf_level` argument (here, we set it to 0.8, or 80%). `avg_comparisons()` allows the user to specify the type of comparison for each variable: here we set `"pairwise"` to calculate pairwise comparisons of each level of `c2`. The output of the two functions is shown in @tbl-marginal-1 and @tbl-marginal-2.

```{r}
#| label: marginal-code
#| eval: false

library(marginaleffects)

avg_comparisons(voi_prop_bm, variables = list(c2 = "pairwise"), conf_level = 0.8, type = "link")
avg_predictions(voi_prop_bm, variables = "vowel", conf_level = 0.8)
```

```{r}
#| label: tbl-marginal-1
#| tbl-cap: "Difference in expected voicing proportion by consonant, averaged across vowels, with 80% CrIs."
#| echo: false

avg_comparisons(voi_prop_bm, variables = list(c2 = "pairwise"), conf_level = 0.8, type = "link") |>
  mutate(across(where(is.numeric), ~round(.x, 3))) |>
  select(-(predicted_lo:tmp_idx)) |> 
  knitr::kable()
```

```{r}
#| label: tbl-marginal-2
#| tbl-cap: "Expected voicing proportion by vowel, averaged across vowels, with 80% CrIs."
#| echo: false

avg_predictions(voi_prop_bm, variables = "vowel", conf_level = 0.8) |>
  mutate(across(where(is.numeric), ~round(.x, 3))) |>
  knitr::kable()
```

# Case study 2: coarticulatory vowel nasalisation {#sec-case-2}

For the second case study we will use data from @carignan2021. The study looked at properties of nasality in German VNC sequences. Here, we will focus on the effect of C voicing (voiceless /t/ vs voiced /d/) on the proportion of nasalisation within the vowel in the VNC sequence. Previous work on coarticulatory nasalisation in English has suggested that vowels followed by an NC sequence where C is voiceless (NT) should show earlier coarticulatory nasalisation than vowels followed by an NC sequence where C is voiced (ND). This pattern has been suggested to be driven by the articulatory and acoustic incompatibility of voicelessness and nasalisation, by which the velum opening gesture of the nasal consonant is pushed away (i.e. earlier) when the consonant following the nasal is voiceless [@fowler2005; @beddor2009; @cho2017; @carignan2015]. Everything else being equal, a greater proportion of vowel nasalisation (from the perspective of time) should be found in vowels followed by NT than in vowels followed by ND.

We will model the proportion of coarticulatory nasalisation in the German short vowels /i, e, a, o, u/ when followed by /nt/ or /nd/, using a Bayesian beta regression model. The proportion was calculated as the proportion of the nasal interval to the duration of the vowel. The nasal interval was defined thus: the interval between the time of peak velocity of velum opening to the offset of the vowel. We will use the results of the regression model to answer the following questions:

1.  Is the nasalisation proportion, on average across vowels, greater in voiceless NC sequences?
2.  Is there individual speaker variation?

@tbl-nasal shows the first ten rows of the data. The data contains the following columns:

-   `speaker` indicates the speaker ID.

-   `label` is the word label as given in the original data.

-   `vowel` is the target vowel in the VNC sequence.

-   `NC` is the NC sequence (voiceless /nt/ or voiced /nd/).

-   `voicing` indicates the voicing of C.

-   `nas_prop` is the proportion of coarticulatory nasalisation of the vowel.

```{r}
#| label: nasal
#| message: false
#| warning: false

nasal <- read_csv("data/carignan2021/nasal.csv")
```

```{r}
#| label: tbl-nasal
#| tbl-cap: "First ten rows of the nasal proportion data."
#| echo: false

nasal |> head(n = 10) |> knitr::kable()
```

```{r}
#| label: fig-nasal
#| fig-cap: "Proportion of coarticulatory nasalisation during the vowel in VNC sequences in German, depending on C voicing."
#| echo: false

nasal |> 
  ggplot(aes(vowel, nas_prop, colour = voicing)) +
  geom_jitter(position = position_jitterdodge(jitter.width = 0.2), alpha = 0.8) +
  scale_color_brewer(type = "qual") +
  labs(x = "Vowel", y = "Nasalisation proportion", colour = "C voicing")

```

@fig-nasal shows the proportion of coarticulatory nasalisation in vowels followed by /nd/ (voiced) vs /nt/ (voiceless) sequences, for the short vowels /i, e, a, o, u/. We can see a pattern of higher nasalisation proportion in vowels followed by /nt/, at least in the vowels /a, i, o/. For /e, u/, the distribution of nasalisation proportion seems to be similar between the voiced and voiceless contexts.

Now onto modelling with a beta regression. Note that a full appropriate model would include further predictors (both constant and varying), but for simplicity here we include only the following predictors: voicing (voiced /nd/ vs voiceless /nt/), vowel (/i, e, a, o, u/), including an interaction between them. As varying terms, we include a varying intercept by speaker and a by-speaker varying slope for voicing and vowel in interaction. As with the model from the first case study, voicing and vowel are coded using indexing, by suppressing the intercept with `0 +`. Here's the code of the model.

```{r}
#| label: nas-prop-bm

nas_prop_bm <- brm(
  nas_prop ~ 0 + voicing:vowel + (0 + voicing:vowel | speaker),
  data = nasal,
  family = Beta,
  cores = 4,
  seed = 3749,
  file = "data/cache/nas_prop_bm"
)
```

Let's inspect the output of `fixef()`, reported in @tbl-nas-prop-fixef.

```{r}
#| label: nas-prop-bm-fixef
#| eval: false

fixef(nas_prop_bm, prob = c(0.1, 0.9))
```

```{r}
#| label: tbl-nas-prop-fixef
#| tbl-cap: "Regression coefficients of a beta regression of nasalisation proportion (`nas_prop_bm`)."
#| echo: false

round(
  fixef(nas_prop_bm, prob = c(0.1, 0.9)),
  digits = 2
) |> knitr::kable()
```

Negative log-odds indicate a proportion that is smaller than 50%, while positive log-odds a proportion that is greater than 50%. Generally, the expected log-odd predictions in @tbl-nas-prop-fixef are negative, indicating an overall tendency for the nasalisation to take less than 50% of the duration of the vowel. Moreover, the predictions are higher for voiceless NC sequences than for voiced NC sequences, indicating a greater proportion of nasalisation in the former. However there is vowel-specific variation, and there doesn't seem to be much of a difference in nasalisation proportion in /e/ and /u/. @fig-nas-prop shows the expected predictions with `conditional_effects()`, which should make the interpretation of the predictions from @tbl-nas-prop-fixef clearer.

```{r}
#| label: fig-nas-prop
#| fig-cap: "Expected nasalisation proportion by vowel and voicing, with 95% CrIs."

conditional_effects(nas_prop_bm, "vowel:voicing")

```

Now that we fitted the model we can use the posterior draws to answer the two research questions (repeated from above):

1.  Is the nasalisation proportion, on average across vowels, greater in voiceless NC sequences?
2.  Is there individual speaker variation?

To answer question 1, we can calculate the average difference in nasalisation proportion by first calculating the average nasalisation across all vowels for voiced and voiceless sequences (see @tbl-nas-draws for the output of this step) and then take the difference of those, similarly to what we have done in the case study in @sec-case-1.

```{r}
#| label: nas-prop-bm-draws
#| warning: false

# extract only coefficient variables starting with "b_"
nas_prop_bm_draws <- as_draws_df(nas_prop_bm, variable = "^b_", regex = TRUE)

nas_prop_bm_draws_long <- nas_prop_bm_draws |> 
  # pivot vowel:c2 columns
  pivot_longer(`b_voicingvoiced:vowela`:`b_voicingvoiceless:vowelu`, names_to = "coeff") |>
  # separate "coeff" labels into type ("b"), vowel and c2
  separate(coeff, into = c("type", "voicing", "vowel"))
```

```{r}
#| label: tbl-nas-draws
#| tbl-cap: "First ten rows of posterior draws from `nas_prop_bm` in long format."
#| echo: false

nas_prop_bm_draws_long |> head(n = 10) |> knitr::kable()
```

Now let's calculate the mean nasalisation proportion within each draw by voicing, and plot the resulting posterior distributions. Note that, as discussed in @sec-case-1, when working with log-odds it is important to first do all necessary calculations in log-odds (here calculate the mean log-odds across vowels) and *then* transform the calculated estimands to proportions/probabilities. The output of the following code is show in @tbl-nas-long-voi and the density plot of the calculated draws is in @fig-nas-prop-bm-draws-long-voicing-plot.

```{r}
#| label: nas-prop-bm-draws-long-voicing

nas_prop_bm_draws_long_voicing <- nas_prop_bm_draws_long |> 
  # grouping by .draw and voicing ensures that averaging applies only within draw and voicing
  group_by(.draw, voicing) |> 
  summarise(
    # calculate the mean value within draw/voicing in log-odds
    value_mean = mean(value),
    # we can now transform log-odds to proportion with plogis()
    value_mean_prop = plogis(value_mean),
    .groups = "drop"
  )
```

```{r}
#| label: tbl-nas-long-voi
#| tbl-cap: "Mean nasalisation proportion by draw and voicing, averaged across vowels (first 10 rows)."
#| echo: false

nas_prop_bm_draws_long_voicing |> head(n = 10) |> knitr::kable()
```

```{r}
#| label: fig-nas-prop-bm-draws-long-voicing-plot
#| fig-cap: "Expected nasalisation proportion by voicing, averaged across vowels."

nas_prop_bm_draws_long_voicing |> 
  ggplot(aes(value_mean_prop, voicing)) +
  stat_halfeye(.width = c(0.6, 0.8))
```

The plot suggests an overall greater nasalisation proportion in voiceless NC sequences. Let's quantify how greater as we did in @sec-case-1. We will use odd-ratios in this context as well, i.e. we will convert log-odds to odd-ratios using the `exp()` (exponential) function (and as before we first calculate the difference and then exponentiate the resulting values, after which we can take summary measures, like means and quantile-based measures such as CrIs). @tbl-nas-prop-bm-diff-quant show the 90, 80 and 60% CrIs of the difference ratio of nasalisation proportion in voiceless vs voiced NC sequences.

```{r}
#| label: nas-prop-bm-diff

nas_prop_bm_diff <- nas_prop_bm_draws_long_voicing |> 
  # pivot data to create one column per voicing with the mean drawn values,
  # with one draw per raw. we need to drop the value_mean_prop col
  select(-value_mean_prop) |> 
  pivot_wider(names_from = voicing, values_from = value_mean) |> 
  mutate(
    # calculate the difference of voiceless and voiced in log-odds
    voicing_diff = voicingvoiceless - voicingvoiced,
    # now transform with exp() to get the ratio difference
    voicing_diff_ratio = exp(voicing_diff)
  )

nas_prop_bm_diff_quant <- nas_prop_bm_diff |> 
  reframe(
    # 90% CrI
    q90 = quantile2(voicing_diff_ratio, probs = c(0.05, 0.95)),
    # 80% CrI
    q80 = quantile2(voicing_diff_ratio, probs = c(0.1, 0.9)),
    # 60% CrI
    q60 = quantile2(voicing_diff_ratio, probs = c(0.2, 0.8)),
  ) |> 
  mutate(across(everything(), ~round(.x, 2)))
```

```{r}
#| label: tbl-nas-prop-bm-diff-quant
#| tbl-cap: "Upper and lower limits of 90, 80 and 60% Credible Intervals of the difference ratio of nasalisation proportion in vowels followed by voiced vs voiceless consonants."
#| echo: false

nas_prop_bm_diff_quant |> knitr::kable()

```

The CrIs of the ratio difference in nasalisation proportion in voiceless vs voiced NC sequences suggest an increase of nasalisation in the voiceless NC sequences, with a 90% probability that the increase is between 23% and 69% of the proportion in voiced NC sequences.

Moving onto question 2: is there individual speaker variation? While in the recent tradition of linguistic research, varying (aka random) effects are used to *control* for differences across participants, it has been proposed to use the estimates of the varying coefficients to investigate individual differences [@tamminga2016]. We will use the `spread_draws()` function from tidybayes [@kay2019] to extract the draws of the varying terms (in brms these are the coefficients that start with `r_`). There is quite a few steps of processing to get from the raw draws to the estimand we need: while we have commented the following code, we encourage readers to test each line sequentially and inspect the intermediate output to fully understand the process. We assume that readers are familiar enough with models with varying terms (aka random effects, mixed-effects, hierarchical, multilevel, nested models). What readers should note is that to obtain the expected predictions of nasalisation proportion for each speaker, the constant terms and the varying terms should be added (since the varying terms indicate the deviation of each speaker from the overall estimate).

```{r}
#| label: nas-prop-r
#| message: false
#| warning: false
library(tidybayes)

nas_prop_r <- nas_prop_bm |> 
  # extract draws from model, only `r_speaker` varying terms
  spread_draws(r_speaker[speaker,voicingvowel]) |> 
  # separate the column voicingvowel to two columns
  separate(voicingvowel, c("voicing", "vowel")) |> 
  # join the draws with the `b_` terms
  left_join(y = nas_prop_bm_draws_long) |> 
  # get the expected log-odd value of each speaker, in each draw
  # this is the sum of the `value` from the b_ terms and the value from the
  # r_speaker term.
  mutate(r_speaker_value = value + r_speaker) |> 
  # group the data for summarise
  group_by(.draw, speaker, voicing) |> 
  # get mean expected log-odds by draw, speaker and voicing (averaging across vowel)
  summarise(r_speaker_value_mean = mean(r_speaker_value)) |> 
  # make the data wider: two columns, one for voiced and one for voiceless
  pivot_wider(names_from = voicing, values_from = r_speaker_value_mean) |> 
  # finally, calculate the difference in expected log-odds of voiceless and voiced
  mutate(voicing_diff = voicingvoiceless - voicingvoiced)
```

@fig-nas-prop-r plots the posterior distributions of the expected log-odd difference of coarticulatory nasalisation in voiceless vs voiced NC sequences (*x*-axis), for each speaker in the data (*y*-axis), as predicted by the model. The red solid vertical line indicates the constant (overall) expected log-odd difference based on the (constant) `b_` terms. The black dashed vertical line marks log-difference 0 (i.e., no difference in proportion of nasalisation between voiceless and voiced NC).

```{r}
#| label: fig-nas-prop-r
#| fig-cap: "Expected log-odd difference of coarticulatory nasalisation in voiceless vs voiced NC sequences for each speaker."
#| warning: false
#| fig-asp: 1.5

nas_prop_r |> 
  ggplot(aes(voicing_diff, reorder(speaker, voicing_diff))) +
  stat_halfeye() +
  geom_vline(xintercept = mean(nas_prop_bm_diff$voicing_diff), colour = "red") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  lims(x = c(-1, 1.5))
```

There is a lot of uncertainty within and between speakers: while the distributions of most speakers are located in the positive range, some expected distributions (see last 5 speakers at the bottom of figure) do substantially span both negative and positive values. In other words, while most speakers are more likely to have a larger nasalisation proportion in voiceless NC sequences, a few might in fact have the opposite pattern. Even among those speakers that do have a more robust positive difference, there is a lot of uncertainty as to the magnitude of the difference.

# Conclusion

In this tutorial we have presented two case studies where the outcome variable is a beta variable, i.e. a numeric continuous variable bounded between 0 and 1. We have shown how to fit Bayesian beta regressions to coarticulatory progressive voicing in voiceless stops in Italian in @sec-case-1 and coarticulatory regressive nasalisation in vowels in German in @sec-case-2. While this tutorial alone will not be sufficient to be able to independently run full Bayesian analyses, it will serve as a first introduction for readers to jump start their learning.
